% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% The "real" document content comes below...

\title{Review of the AlphaGo Article}
%\author{}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\section{Introduction}
The AlphaGo agent made big breakthrough in Artificial Intelligence recently by beating top Go players very stably. This remarkable agent is built upon the most recent start-of-art techniques in deep learning. We are going to give a short review on AlphaGo in this report.


\section{Goals}

Two common tasks for a game agent are to select moves and to evaluate board positions. The paper is aimed to make improvements on these two important tasks. It introduces convolutional neural networks to study the patterns in a value networks to evaluate board positions and policy networks to select moves.


\section{Techniques Introduced}

Main techniques used in the agent include the following:

Convolutional Neural Networks. It regards the $19$x$19$ board as an input image to feed into convolutional layers to construct a representation of the posotion. These neural networks are used to reduce the effective depth and breadth of the search tree. The positions are evaluated using a value network while actions are sampled using a policy network. 

Policy Networks. The policy networks are trained in two stages. The first stage is the supervised learning with previous human experts' choices of moves. the second stage is the reinforcement learning by playing the game against itself. 

Value Networks. These are used to evaluate positions. They are trained with reinforcement learning with a generated self-play data set.

Search. Searching with the policy and value networks is done using Monte-Carlo Tree Search. The tree search is efficiently combined with the neural networks by an asynchronous multi-threaded search.


\section{Results}

Playing strength of AlphaGo is evaluated with other existing programs including Crazy Stone, Zen, Pachi and Fuego. AlphaGo consistently beat these programs. 

The most significant success of AlphaGo is its play against human top experts:

AlphaGo Fan won $5:0$ agains Fan Hui.

AlphaGo Lee won $4:1$ agains Lee Sedol.

AlphaGo Master won $60:0$ against professional players.

AlphaGo Zero won $100:0$ against AlphaGo Lee and $89:11$ against AlphaGo Master.

In May 2017, AlphaGo won $3:0$ against the current world No.$1$ ranking player Ke Jie.



\end{document}
